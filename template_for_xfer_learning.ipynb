{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template_for xfer_learning.ipynb",
      "provenance": [],
      "mount_file_id": "1Mfb7zWgtUGFtcJWWHZ3RIRWzxMQtZ395",
      "authorship_tag": "ABX9TyMOFCPRN9eomwDFGriue6MC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunal-git-002/extra-work/blob/master/template_for_xfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csZsWa-71Rbi",
        "colab_type": "text"
      },
      "source": [
        "***transfer learning***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYGpDt7R1cRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input,Lambda,Dense,Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import  image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IFSPDQt2Seq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size=[224,224]#vgg 16  work on this img size\n",
        "\n",
        "tr_path=\"dataset/train\"\n",
        "te_path=\"dataset/test\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZVWVN2H3kxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "caf1b4fa-cf54-4316-e94f-566262e794bf"
      },
      "source": [
        "#add preprocessing layer to the front of VGG\n",
        "vgg=VGG16(input_shape=img_size + [3],#chaneel 3 for rgb\n",
        "          weights=\"imagenet\",\n",
        "          include_top=False)#last layer of vgg is removed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElZPiNd24Yz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dont train existing weights\n",
        "#becz it is already trained\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable=False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBdqYNih41DG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the number of classes for op layer\n",
        "folders=glob(\"/content/drive/My Drive/CNN_prac/data/transfer learning/train/*\")\n",
        "\n",
        "#or \n",
        "#use os.lisdiritems vadu\n",
        "\n",
        "folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aw81JQV5EJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=Flatten()(vgg.output)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUdYP4De5WJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=Dense(len(person),activation=\"softmax\")(x)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tItV-Bz-5mFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model\n",
        "model=Model(inputs=vgg.input,outputs=pred)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gHz-ETN6IKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPLkAeTU7P92",
        "colab_type": "text"
      },
      "source": [
        "***image augumentation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKMGmGZg6hmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f9a947de-2431-4d2f-8d85-9e1214563ca9"
      },
      "source": [
        "tr_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "te_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "tr_set=tr_datagen.flow_from_directory(\n",
        "    \"/content/drive/My Drive/CNN_prac/data/transfer_learning/train \",\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "te_set=te_datagen.flow_from_directory(\n",
        "    \"/content/drive/My Drive/CNN_prac/data/transfer_learning/test\",\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\"    \n",
        ")\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x7f5ab1c67c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqZHaGeB7qQd",
        "colab_type": "text"
      },
      "source": [
        "***model trainning***"
      ]
    }
  ]
}